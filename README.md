# GoBike-SystemData-Analysis
Bay Wheels's trip data Analysis using Jupyter Notebook

## Introduction
This project is the final task of the Udacity Data Analyst Nano Degree.
The dataset chosen to perform the analysis is the [Ford GoBike System Data](https://www.lyft.com/bikes/bay-wheels/system-data).
This data set includes information about individual rides made in a bike-sharing system covering the greater San Francisco Bay area.


## Learning objectives
### Why this project?
Data visualization is an important skill that is used in many parts of the data analysis process. 
**Exploratory** data visualization generally occurs during and after the data wrangling process, and is the main method that you will use to understand the patterns and relationships present in your data. This understanding will help you approach any statistical analyses and will help you build conclusions and findings. This process might also illuminate additional data cleaning tasks to be performed. 
**Explanatory** data visualization techniques are used after generating your findings, and are used to help communicate your results to others. Understanding design considerations will make sure that your message is clear and effective. In addition to being a good producer of visualizations, going through this project will also help you be a good consumer of visualizations that are presented to you by others.

### What will I learn?
- Supplement statistics with visualizations to build understanding of data.
- Choose appropriate plots, limits, transformations, and aesthetics to explore a dataset, allowing you to understand distributions of variables and relationships between features.
- Use design principles to create effective visualizations for communicating findings to an audience.

## Analysis Description
This project has two parts that demonstrate the importance and value of data visualization techniques in the data analysis process. 

In the first part, I'll use Python visualization libraries to systematically explore a dataset, starting from plots of single variables and building up to plots of multiple variables. 

In the second part, I'll produce a short presentation that illustrates interesting properties, trends, and relationships discovered in the dataset. The primary method of conveying the findings will be through transforming your exploratory visualizations from the first part into polished, explanatory visualizations.

## Contents
.ipynb file where the analysis has been developed, contains code with Markdown cells from Jupyter Notebook. 
.html file output of the .ipynb converted to web version for easy viewing 
.csv files with the data used to conduct the analysis


## Pre-requisites
No installation is needed to view the analysis. To reproduce the project an installation of Python 3.5 and the following libraries is needed:

- pandas
- NumPy
- Matplotlib
- Seaborn
- csv 
A link to instructions for the tools installations written by me in a blog post [here](https://medium.com/swlh/setting-up-a-python-postgres-environment-for-data-science-abd6503c7d0a)
